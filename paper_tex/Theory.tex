\section{Learning-to-Match Framework}\label{sec:framework}
Within this framework, we perform treatment effect estimation using following three stages: 1) learning a distance metric, 2) matching samples, and 3) estimating CATEs. 

We denote the $p$ dimensional covariate vector space as $\mathcal{X}\subset \mathbb{R}^p$ and the unidimensional outcome space by $\mathcal{Y} \subset \mathbb{R}$. Let $\mathcal{T}$ be a finite label set of treatment indicators (in this paper we consider only the binary case). Let $\mathcal{Z}=\mathcal{X}\times\mathcal{Y}\times\mathcal{T}$ such that $z=(\x,y,t)\in \mathcal{Z}$ means that $\x\in\mathcal{X}$, $y\in\mathcal{Y}$ and $t\in\mathcal{T}$. Let $\mu$ be an unknown probability distribution over $\mathcal{Z}$ such that $\forall z \in \mathcal{Z}, ~ \mu(z)>0$. We assume that $\mathcal{X}$ is a compact convex space with respect to $\|\cdot\|_2$, thus there exists a constant $\mathbf{C}_x$ such that $\|\x\|_2\leq\mathbf{C}_x$. Also, $|y|\leq\mathbf{C}_y$. A distance metric is a symmetric, positive definite function with two arguments from $\mathcal{X}$ such that $\dis: \mathcal{X}\times\mathcal{X} \to \mathbb{R}^+$. A distance metric must obey the triangle inequality. Let $\mathcal{S}_n$ denote a set of $n$ observed units $\{s_1,...,s_n\}$ drawn i.i.d. from $\mu$ such that $\forall i, ~s_i \in \mathcal{Z}$. We parameterize $\dis$ with parameter $\mathcal{M}(\cdot)$, explicitly calling it $\dis_\mathcal{M}$, and let $\mathcal{M}(\mathcal{S}_n)$ denote the parameter learned using $\textsc{MALTS}$ methodology which is described in Section~\ref{sec:method}. 
For ease of notation, we will denote the observed sample of treated units as $\mathcal{S}^{(T)}_n := \{s^{(T)}_i = (\x_i,y_i,t_i)~|~ s^{(T)}_i \in \mathcal{S}_n \text{ and } t_i = T \}$ and the observed sample of control units as $\mathcal{S}^{(C)}_n := \{s^{(C)}_i = (\x_i,y_i,t_i)~|~ s^{(C)}_i \in \mathcal{S}_n \text{ and } t_i = C \}$.
We assume no unobserved confounders and standard ignorability assumptions, i.e.  $\forall i,~ (Y^{(T)},Y^{(C)})~ \indep ~T ~|~ (X=\x_i)$ \citep{Rubin2005}. For each individual unit $s_i = (\x_i,y_i,t_i) \in \mathcal{Z}$ we define its conditional average treatment effect (or individualized treatment effect) as the difference of potential outcomes of unit $i$ under the treatment and control, $\tau(\x_i) = \mathbbm{E}\left[Y^{(T)} - Y^{(C)} | X=\x_i \right] = y^{(T)}(\x_i) -y^{(C)}(\x_i)$. For notational simplicity we sometimes refer $y^{(T)}(\x_i)$ as $y^{(T)}_i$ and $y^{(C)}(\x_i)$ as $y^{(C)}_i$ We use the $\;\widehat{}$ (hat) notation to refer to estimated values. 
%using the given covariate vector.
% In our framework, a learning-to-match algorithm consist of three modeling decisions: the form of distance metric used for matching, the method of learning parameters of that distance metric, and the method of matching. 
%A training set is used to train the parameters of the distance metric, and that learned distance metric is used on the rest of the sample in the test-set for matching and CATE prediction. 


Our goal is to minimize the expected loss between estimated treatment effects $\widehat{\tau}(\x)$ and true treatment effects $\tau(\x)$ across target population $\mu(z)$ (this can either be a finite or super-population).

Let the population expected loss be:
\begin{eqnarray*}
\E\left[ \ell(\widehat{\tau}(\x),\tau(\x))\right]
=
\int \ell(\widehat{\tau}(\x),\tau(\x))d\mu
=
\int \ell(\hat{y}^{(T)}(\x)-\hat{y}^{(C)}(\x), {y}^{(T)}(\x)-{y}^{(C)}(\x)) d\mu.
\end{eqnarray*}
% \todo{should this expectation be over X or over X and T?}
We use absolute loss, $\ell(a,b)=|a-b|$. 
For a finite random i.i.d$.$ sample $\{s_i=(\x_i,y_i,t_i)\}^n_{i=1}$ from the distribution $\mu$, we could estimate the sample average loss as 
\begin{eqnarray*}
% \E \ell(\widehat{\tau}(\x),\tau(\x))
% \approx
\frac{1}{n}\sum_{i=1}^n \ell(\hat{y}^{(T)}(\x_i)-\hat{y}^{(C)}(\x_i), {y}^{(T)}(\x_i)-{y}^{(C)}(\x_i)),
\end{eqnarray*}
where $y^{(T)}(\x_i)$ and $y^{(C)}(\x_i)$ are the counterfactual outcome values for the units in the sample $\{s_i=(\x_i,y_i,t_i):i=1,\dots,n\}$.
However, the difficulty in causal inference is that we only observe treatment outcomes $y^{(T)}(\x_i)$ or control outcomes $y^{(C)}(\x_i)$ for an individual $i$ in the sample. Hence, we cannot directly calculate the treatment effect for any individual. For units in the treatment set we know $y^{(T)}(\x_i)$ and so we replace $\hat{y}^{(T)}(\x_i)$ by $y^{(T)}(\x_i)$, and analogously for units in the control set. Thus breaking the sum into treatment and control group:
\begin{eqnarray*}
% \E_{\mu} \ell(\widehat{\tau}(\x),\tau(\x))
% \approx&
\frac{1}{n_t}
\sum_{i \in \textrm{treated}} \ell(y^{(T)}(\x_i)-\hat{y}^{(C)}(\x_i), {y}^{(T)}(\x_i)-{y}^{(C)}(\x_i))\\
+ \frac{1}{n_c}
\sum_{i \in \textrm{control}} \ell(\hat{y}^{(T)}(\x_i)-y^{(C)}(\x_i), {y}^{(T)}(\x_i)-{y}^{(C)}(\x_i)).
\end{eqnarray*}

 For a unit in the treatment set $s^{(T)}_i$, we use matching to estimate the control outcome $\hat{y}^{(C)}(\x_i)$ by an average of the control outcomes within its matched group that we can observe. Let us define the \textit{matched group} $\MG$ under the distance metric $\dis_{\mathcal{M}}$ parameterized by $\mathcal{M}$ for treated unit $s_i$ in terms of the observed control units $\mathcal{S}^{(C)}_n = \{s_k^{(C)}\}_{k}$ indexed by $k$, which are the K-nearest-neighbors from set $\mathcal{S}_n$ under the distance metric $\dis_{\mathcal{M}}$:
\begin{eqnarray}\label{eqn:mg}
\MG(s_i,\dis_{\mathcal{M}},\mathcal{S}_n,K) =
KNN^{\mathcal{S}_n}_{\mathcal{M}}(\x_i,C) := %\\\nonumber
\bigg\{s_k:\bigg[\sum_{s_l\in\mathcal{S}^{(C)}_n}\mathbbm{1}\Big(\dis_{\mathcal{M}}(
%\LL
\x_l,\x_i)<\dis_{\mathcal{M}}(\x_k,\x_i)\Big)\bigg] < K \bigg\}.
\end{eqnarray}
We allow reuse of units in multiple matched groups. Thus for a chosen estimator $\phi$,
\begin{equation}\label{eqn:yhat}
\hat{y}^{(C)}(\x_i) = \phi\left(\MG(s_i,\dis_{\mathcal{M}},\mathcal{S}_n,K)\right)
% \frac{1}{K}\sum_{k\in\MG(s_i,\dis_{\mathcal{M}},\mathcal{S}_n,K)}y_k,
\end{equation}
where $K$ is the size of the matched group $\MG(s_i,\dis_{\mathcal{M}},\mathcal{S}_n,K)$. A simple example of $\phi$ is the mean estimator, i.e. $\phi\left(\MG(s_i,\dis_{\mathcal{M}},\mathcal{S}_n,K)\right) =  \frac{1}{K}\sum_{k\in\MG(s_i,\dis_{\mathcal{M}},\mathcal{S}_n,K)}y_k$. However, one can choose the estimator to be a weighted mean, linear regression or a non-parametric model like random-forest. 

Our framework learns a distance metric
from a separate training set of data (not the estimation data considered in the averages above), and
we denote this training set by $\mathcal{S}_{tr}$. To learn $\dis_{\mathcal{M}}$, we minimize the following:
\begin{eqnarray*}
\mathcal{M}(\mathcal{S}_{tr})\in
\textrm{arg}\min_{\mathcal{M}}\left[ 
\begin{array}{l}
\sum_{s_i\in \mathcal{S}^{(T)}_{tr}}
\left( y_i - \hat{y}^{(T)}(\x_i)
\right)^2 \\
+ \sum_{s_i\in \mathcal{S}^{(C)}_{tr}}
\left( y_i - \hat{y}^{(C)}(\x_i)
\right)^2\end{array}
\right],  
\end{eqnarray*}
where $\hat{y}^{(C)}(\x_i)$ is defined by Equations (\ref{eqn:mg}) and (\ref{eqn:yhat}) including its dependence on the $\distance$ $\dis_{\mathcal{M}}$, which is parameterized by
 $\mathcal{M}$,
using the training data for creating matched groups. $\hat{y}^{T}(\x_i)$ is defined analogously.

Once $\mathcal{M}(\mathcal{S}_{tr})$ is learned from the training set, it is used for estimation on the estimation data.

\subsection{Smooth Distance Metric and Treatment Effect Estimation}
In this subsection, we discuss that if a distance metric is a smooth distance metric then we can estimate the individualized treatment effect using a finite sample with high probability. First, let us define a smooth distance metric.
\begin{define}
\textbf{(Smooth Distance Metric)} $\dis:\mathcal{X}\times\mathcal{X}\to\mathbb{R}^{+}$ is a smooth distance metric if there exists a monotonically increasing bounded function $\alpha_\dis(\cdot)$ with zero intercept and a constant $0 \leq \beta_\dis<1$, such that $\forall z_i,z_l \in \mathcal{Z}$ if $t_i=t_l$ and $\dis(x_i,x_l)\leq\epsilon$ then $P\left(|Y_i-Y_l|\geq\alpha_\dis(\epsilon)\right)\leq\beta_\dis $.
\end{define}
 
 In the following text, the function $1NN$ refers to the \textit{1-nearest-neighbor} version of $KNN$ which returns the nearest neighbor of the query point.

\begin{theorem}
\label{th: smoothtau}
Given a smooth distance metric $\dis_{\mathcal{M}}$, if we estimate individualized treatment effect $\hat{\tau}(\cdot)$ for any given $z=(\x,y,t) \in \mathcal{Z}$  by nearest neighbor matching on a finite sample $\mathcal{S}_n\overset{i.i.d}{\sim}\mu(\mathcal{Z}^n)$, using distance metric $\dis_{\mathcal{M}}$, then the estimated individualized treatment effect $\hat{\tau}(\x)$ and the true individualized treatment effect $\tau(\x)$ are farther than $\epsilon$ with probability less than $\delta(\epsilon,\dis_\mathcal{M},n)$:
$$ P_{\mathcal{S}_n \sim \mu(\mathcal{Z}^n)}\Big( |\hat{\tau}(\x) - \tau(\x)| \geq \epsilon \Big) \leq \delta(\epsilon,\dis_\mathcal{M},n). $$
\end{theorem}

% \textbf{Proof (Theorem~\ref{th: smoothtau})}.
 Theorem~\ref{th: smoothtau} follows from Lemma~\ref{lm: smoothy} in the appendix which proves that we can estimate counterfactual outcomes $y$ correctly with high probability using nearest neighbor matching under a smooth distance metric, and Lemma~\ref{lm: ytotau} in the appendix which proves that estimating counterfactual outcomes, $y$, correctly with high probability leads to estimating CATEs, $\tau$, correctly with high probability.
 
%  In Section~\ref{sec:Experiments}, Figure~\ref{fig:var_covariate_match}(b) shows that as the size of the estimation set increases, the mean error-rate for predicting CATE using any smooth distance metric decreases. We also show that using the MALTS methodology described in Section~\ref{sec:method}, we achieve significantly lower error-rate than a predefined Mahalanobis distance metric.



